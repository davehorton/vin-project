{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JWuyniZhFN3F"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"livekit/turn-detector\")\n",
        "\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"I am John.\"},\n",
        "#     {\"role\": \"user\", \"content\": \"What is your last name?\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"Smith.\"},\n",
        "#     {\"role\": \"user\", \"content\": \"How do you spell the first\"}\n",
        "# ]\n",
        "\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"I am John.\"},\n",
        "#     {\"role\": \"user\", \"content\": \"What is your last name?\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"Smith.\"},\n",
        "# ]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "      \"timestamp\": \"00:00:00\",\n",
        "      \"role\": \"Speaker 0\",\n",
        "      \"content\": \"Ma'am, cars. Can I help you?\"\n",
        "    },\n",
        "    {\n",
        "      \"timestamp\": \"00:00:02\",\n",
        "      \"role\": \"Speaker 1\",\n",
        "      \"content\": \"Oh, hi. I'm trying to find out how much it would cost for you to pick up something from prior report. It's not it's not furniture or anything like that. Just a a little bag Okay. For my son.\"\n",
        "    },\n",
        "    {\n",
        "      \"timestamp\": \"00:00:12\",\n",
        "      \"role\": \"Speaker 1\",\n",
        "      \"content\": \"And drop it off at, in washing sorry. Pick it up from Washington House and drop it off at 3 Parkside, Rutland Road, E 97 J U.\"\n",
        "    },\n",
        "    {\n",
        "      \"timestamp\": \"00:00:28\",\n",
        "      \"role\": \"Speaker 0\",\n",
        "      \"content\": \"20 Pound 10.\"\n",
        "    },\n",
        "    {\n",
        "      \"timestamp\": \"00:00:30\",\n",
        "      \"role\": \"Speaker 1\",\n",
        "      \"content\": \"Okay. Is it possible to arrange that now?\"\n",
        "    }]"
      ],
      "metadata": {
        "id": "e_M9h4vE5gTg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "      # \"timestamp\": \"00:00:00\",\n",
        "      # \"role\": \"Speaker 0\",\n",
        "      # \"content\": \"Ma'am, cars. Can I help you?\"\n",
        "    # },\n",
        "    # {\n",
        "      # \"timestamp\": \"00:00:02\",\n",
        "      # \"role\": \"Speaker 1\",\n",
        "      # \"content\": \"Oh, hi. I'm trying to find out how much it would cost for you to pick up something from prior report.\"\n",
        "    # },\n",
        "    # {\n",
        "      # \"timestamp\": \"00:00:12\",\n",
        "      # \"role\": \"Speaker 1\",\n",
        "      # \"content\": \"And drop it off at, in washing sorry. Pick it up from Washington House and drop it off at 3 Parkside, Rutland Road, E 97 J U.\"\n",
        "    # },\n",
        "    # {\n",
        "      \"timestamp\": \"00:00:28\",\n",
        "      \"role\": \"Speaker 0\",\n",
        "      \"content\": \"20 Pound 10.\"\n",
        "    # },\n",
        "    # {\n",
        "    #   \"timestamp\": \"00:00:30\",\n",
        "    #   \"role\": \"Speaker 1\",\n",
        "    #   \"content\": \"Okay. Is it possible to arrange that now?\"\n",
        "    }]"
      ],
      "metadata": {
        "id": "6H_fpXnyjlLe"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Format messages using the chat template\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=False,\n",
        "    add_special_tokens=False,\n",
        "    tokenize=False\n",
        ")\n",
        "\n",
        "# Remove the EOU token from current utterance\n",
        "# ix = text.rfind(\"<|im_end|>\")\n",
        "# text = text[:ix]\n"
      ],
      "metadata": {
        "id": "24voTM4AFPg2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U7WeAShyFeWU",
        "outputId": "499c1e40-3092-4b51-9a45-1f2fc7c4337a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|><|Speaker 0|>20 Pound 10.<|im_end|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"livekit/turn-detector\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_H2tW30nMfP",
        "outputId": "7f486e49-2bb1-4976-e050-bee04aca2dbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at livekit/turn-detector and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTZVzRlYBgpY",
        "outputId": "e210ef3c-6aa2-44fc-93f5-f40a53abbaee"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"eos_token_id\": 0,\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 576,\n",
              "  \"initializer_range\": 0.041666666666666664,\n",
              "  \"intermediate_size\": 1536,\n",
              "  \"is_llama_config\": true,\n",
              "  \"max_position_embeddings\": 8192,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 9,\n",
              "  \"num_hidden_layers\": 30,\n",
              "  \"num_key_value_heads\": 3,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_interleaved\": false,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 100000,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.51.3\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 49154\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "Gtgi9D90un6o"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYIiOUJLurTw",
        "outputId": "189a9521-ede6-4ade-e741-7371ff7d0691"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1,    44,   108, 15024,  5251,   216,    32,   108,    46,    34,\n",
              "            32,   377,   620,   216,    33,    32,    30,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aokCX6Q-uwgD",
        "outputId": "6a893b18-4c72-4206-d3c6-07d47a477d7b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1,    44,   108, 15024,  5251,   216,    32,   108,    46,    34,\n",
              "            32,   377,   620,   216,    33,    32,    30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Get prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    print(\"probabilities\", probabilities)\n",
        "    # Use index 1 for the positive class probability\n",
        "    eou_probability = probabilities[0, 1].item()\n",
        "\n",
        "print(f\"End of utterance probability: {eou_probability}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMs9-jvXvq52",
        "outputId": "006b9739-779a-4069-ab59-3ff5839a1f2c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probabilities tensor([[0.4733, 0.5267]])\n",
            "End of utterance probability: 0.526699960231781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkFFLneiwDDe",
        "outputId": "8e69d556-d87e-4d66-8c28-bead054c95b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutputWithPast(loss=None, logits=tensor([[0.8110, 1.0441]]), past_key_values=<transformers.cache_utils.DynamicCache object at 0x7c5ab3ac9650>, hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Role of Past Key Values\n",
        "The past_key_values attribute, represented as a DynamicCache object, is crucial for real-time applications.\n",
        "It caches the key and value states from the transformer model, allowing subsequent inputs to be processed efficiently without recomputing the entire history. This is particularly important for streaming audio, where the model processes input incrementally, as seen in LiveKitâ€™s implementation for EOU detection.\n",
        "\n"
      ],
      "metadata": {
        "id": "V7vC-9mrxeyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woAfPF5xwR0c",
        "outputId": "365583fa-77f6-4987-b1c0-8e336292839b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__contains__',\n",
              " '__dataclass_fields__',\n",
              " '__dataclass_params__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__ior__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__or__',\n",
              " '__post_init__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__ror__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'attentions',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'fromkeys',\n",
              " 'get',\n",
              " 'hidden_states',\n",
              " 'items',\n",
              " 'keys',\n",
              " 'logits',\n",
              " 'loss',\n",
              " 'move_to_end',\n",
              " 'past_key_values',\n",
              " 'pop',\n",
              " 'popitem',\n",
              " 'setdefault',\n",
              " 'to_tuple',\n",
              " 'update',\n",
              " 'values']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.past_key_values[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUJ1xZywwWTh",
        "outputId": "a961187b-cf34-49ef-9b8e-c10a55023a5e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[ 2.8481e+00,  1.5320e+00, -3.4065e+00,  ..., -7.0517e-01,\n",
              "            -5.0408e-01, -2.7594e+00],\n",
              "           [-2.8290e+00, -3.3621e+00, -2.8275e+00,  ...,  1.8865e+00,\n",
              "            -8.7491e-01,  1.0558e+00],\n",
              "           [-5.8378e+00, -2.2527e+00, -8.6742e-01,  ...,  9.5778e-01,\n",
              "             1.6808e-01, -1.6429e+00],\n",
              "           ...,\n",
              "           [ 6.5366e+00,  2.3378e+00,  1.8057e+00,  ...,  1.0893e+00,\n",
              "            -1.4958e+00, -7.6381e-01],\n",
              "           [ 1.5594e+00,  1.9164e+00,  3.6701e+00,  ...,  2.6238e-01,\n",
              "            -2.4472e+00, -8.8869e-01],\n",
              "           [-4.1201e-01,  2.8317e-01,  6.9000e-01,  ..., -7.2752e-02,\n",
              "            -4.4232e-01, -1.3182e+00]],\n",
              " \n",
              "          [[ 6.1872e-01, -6.3033e-01,  1.0066e+00,  ..., -2.4309e+00,\n",
              "            -1.0370e+00, -5.1346e-01],\n",
              "           [ 1.7875e+00, -7.5878e-01, -4.0836e-01,  ..., -7.8726e-01,\n",
              "             1.6954e+00,  3.6208e-01],\n",
              "           [-1.5504e-01,  2.5183e+00, -2.1796e+00,  ..., -2.2357e-01,\n",
              "             9.7780e-01, -5.1814e-01],\n",
              "           ...,\n",
              "           [-8.4228e-01, -6.7840e-01, -6.5321e-01,  ...,  1.3832e+00,\n",
              "            -7.7998e-01, -6.5000e-01],\n",
              "           [ 4.4362e-02, -2.3686e+00, -3.7412e-01,  ...,  7.3580e-01,\n",
              "            -3.9621e-01, -1.0473e+00],\n",
              "           [-7.4276e-02, -2.2594e-02, -2.3843e-03,  ..., -9.1667e-01,\n",
              "             1.6124e+00, -1.0626e-01]],\n",
              " \n",
              "          [[ 3.2301e+00, -1.9152e+00,  2.5455e+00,  ...,  1.8040e-01,\n",
              "             2.3058e-01,  1.2421e+00],\n",
              "           [-1.3154e-01, -3.6770e-01,  1.0617e+00,  ...,  3.4605e-01,\n",
              "             1.0568e-01, -1.4216e+00],\n",
              "           [-8.8404e-01, -4.6652e-01,  8.6762e-01,  ...,  1.4986e-01,\n",
              "             1.1159e-01, -5.4615e-01],\n",
              "           ...,\n",
              "           [ 1.3381e+00,  7.6683e-01, -1.5739e+00,  ...,  3.2456e-01,\n",
              "             1.1876e+00, -8.7797e-01],\n",
              "           [ 2.0738e+00, -5.0067e-01, -2.2135e+00,  ...,  7.5097e-01,\n",
              "            -7.6836e-01, -1.0797e+00],\n",
              "           [ 3.3767e-01, -3.3698e-01, -4.9853e-01,  ..., -2.6976e-01,\n",
              "             3.4132e-01, -3.7825e-01]]]]),\n",
              " tensor([[[[-0.7043, -0.1563,  0.3914,  ...,  0.0624, -0.0405, -0.4977],\n",
              "           [-0.2661,  0.2020,  0.0067,  ...,  0.0277, -0.1926,  0.9239],\n",
              "           [-0.2625,  0.2240,  0.1015,  ...,  0.1036,  0.1535,  0.8250],\n",
              "           ...,\n",
              "           [ 0.2332, -0.3811, -0.0722,  ..., -0.2762, -0.8404,  0.6392],\n",
              "           [ 0.8997, -0.9391,  0.1849,  ...,  0.0829,  0.4955,  0.2760],\n",
              "           [ 0.0203,  0.0135,  0.0013,  ..., -0.0185, -0.0307,  0.1408]],\n",
              " \n",
              "          [[-0.5466,  0.3711, -0.2577,  ...,  0.1706,  0.0363,  0.1206],\n",
              "           [ 0.3330, -0.3979, -0.4078,  ..., -0.5574,  0.5306,  0.0416],\n",
              "           [ 0.6209,  0.2305,  0.4237,  ..., -0.4837, -0.0985,  0.2539],\n",
              "           ...,\n",
              "           [ 0.2583,  0.3084, -0.0766,  ..., -0.0259,  0.3748, -0.0681],\n",
              "           [ 0.4297, -0.1827,  0.3013,  ..., -0.1835,  0.2953, -0.0247],\n",
              "           [ 0.0016,  0.0102, -0.0127,  ..., -0.0278, -0.0024, -0.0058]],\n",
              " \n",
              "          [[ 0.0011,  0.4955,  0.0394,  ...,  0.3128,  0.0334,  0.1821],\n",
              "           [ 0.0200, -0.0297,  0.1133,  ..., -0.1520,  0.0111, -0.0142],\n",
              "           [ 0.2996, -0.1646,  0.2457,  ..., -0.1497,  0.0753,  0.2928],\n",
              "           ...,\n",
              "           [-0.1328,  0.0875,  0.1060,  ..., -0.0867, -0.3694, -0.0472],\n",
              "           [-0.1642, -0.1975, -0.0727,  ..., -0.2933,  0.1870, -0.1678],\n",
              "           [-0.0055, -0.0400,  0.0029,  ...,  0.0161,  0.0257, -0.0452]]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    print(\"probabilities\", probabilities)\n",
        "    # Use index 1 for the positive class probability\n",
        "    eou_probability = probabilities[0, 1].item()\n",
        "\n",
        "print(f\"End of utterance probability: {eou_probability}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py_4fkwBFfAT",
        "outputId": "6c939cde-0bbf-4b52-bb5b-c904bd9f6be9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probabilities tensor([[0.8651, 0.1349]])\n",
            "End of utterance probability: 0.1348775029182434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-4B3lfGm3Ww",
        "outputId": "9755ca39-4819-4134-8fe9-8ed7556fd34e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutputWithPast(loss=None, logits=tensor([[-2.3683, -0.0288]]), past_key_values=<transformers.cache_utils.DynamicCache object at 0x795f75b3c350>, hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cCr6aKymF1Zr",
        "outputId": "c8257cee-1af8-43fd-fcc0-79ea72b8ed6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<|im_start|><|Speaker 0|>Ma'am, cars. Can I help you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JlqR3oZGDvf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}